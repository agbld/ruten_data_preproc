{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857ec11b",
   "metadata": {},
   "source": [
    "### clean lexicon (加上##的規則)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d001324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021/12   : 關閉 OutPutLexicon.merge_non_english() 改使用 sub('[^\\u4e00-\\u9fa5A-Za-z0-9]+','')\n",
    "# 2021/12/24: 字典中只留下中文、英文、數字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dffbe3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "counter = 0\n",
    "\n",
    "class OutPutLexicon():\n",
    "    '''\n",
    "    Output lexicon txt file of each class in cilin \n",
    "    call \"start()\" function to get lexicon txt file\n",
    "    '''\n",
    "    def __init__(self,file_name):\n",
    "\n",
    "        #with open(file_name, newline='', encoding=\"utf-8\") as jsonfile: # 本地json\n",
    "        #    self.data = json.load(jsonfile)\n",
    "        \n",
    "        #self.data = requests.get(url='http://127.0.0.1:5000/getCilinJson').json()\n",
    "        self.data = requests.get(url='http://140.118.170.215:7000/getCilinJson').json() # get cilin json (實驗室)\n",
    "        #self.data = requests.get(url='http://140.118.170.215:5000/getCilinJson').json() # get cilin json (實驗室)\n",
    "        #self.data = requests.get(url='http://122.116.133.54:5000/getCilinJson').json() # 可東ip\n",
    "        \n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Output lexicon txt file of each class in cilin \n",
    "        \"\"\"\n",
    "        counter = 0   # count total number of word in lexicon\n",
    "        self.export_class_name = []\n",
    "        all_class_name = self.data.keys()\n",
    "        \n",
    "        for class_name in all_class_name:\n",
    "            class_lexicon = self.class_lexicon(class_name)  # get lexicon of corresponding class name\n",
    "            print(class_name,\"/\",len(class_lexicon))\n",
    "            \n",
    "            if class_name == 'Brand 品牌': # since we have both cilin lexicon and pchome lexicon, we need to merge them together\n",
    "                pchome_brand = self.read_pchome_file(r'C:\\Users\\EE303\\OneDrive\\PChome\\相似同義詞輸出\\pchome_data\\brand.txt')\n",
    "                merge_lexicon = class_lexicon.union(pchome_brand) # merge cilin lexicon and pchome lexicon together (union)\n",
    "                self.write_txt(class_name,merge_lexicon)\n",
    "                print(\"merge\",class_name,\"/\",len(merge_lexicon))\n",
    "                counter = counter + len(merge_lexicon)\n",
    "                \n",
    "            if class_name == 'Type 種類':\n",
    "                pchome_type = self.read_pchome_file(r'C:\\Users\\EE303\\OneDrive\\PChome\\相似同義詞輸出\\Lexicon\\Type_pchome_only.txt')\n",
    "                merge_lexicon = class_lexicon.union(pchome_type) # merge cilin lexicon and pchome lexicon together (union)\n",
    "                self.write_txt(class_name,merge_lexicon)\n",
    "                print(\"merge\",class_name,\"/\",len(merge_lexicon))\n",
    "                counter = counter + len(merge_lexicon)\n",
    "\n",
    "            else: \n",
    "                self.write_txt(class_name,class_lexicon)\n",
    "                counter = counter + len(class_lexicon)\n",
    "        print(\"number of term in Lexicon: \", counter)\n",
    "        #print(\"self.export_class_name:\", self.export_class_name)\n",
    "        \n",
    "        return self.export_class_name\n",
    "    \n",
    "    def write_txt(self,class_name,class_lexicon):\n",
    "        \"\"\"\n",
    "        write lexicon txt file of input lexicon\n",
    "        :Input 1: [String], class_name\n",
    "        :Input 2: [Set], lexicon of each class\n",
    "        :Output:  [.txt file]\n",
    "        \"\"\"\n",
    "        lines = sorted(class_lexicon)\n",
    "        \n",
    "        flag = re.search('[A-Za-z-]+',class_name)\n",
    "        class_name = class_name[flag.span()[0]:flag.span()[1]] #\n",
    "        \n",
    "        self.export_class_name.append(class_name.lower())\n",
    "        \n",
    "        with open('Lexicon_merge/{}.txt'.format(class_name.lower()), 'w', encoding='UTF-8') as f:\n",
    "            for line in lines:\n",
    "                if line:\n",
    "                    #line = line.replace(\" \", \"\")\n",
    "                    f.write(line.strip('\\n'))\n",
    "                    f.write('\\n')\n",
    "                \n",
    "    def read_pchome_file(self,file_path):\n",
    "        \"\"\"\n",
    "        read external lexicon (txt) \n",
    "        :Input 1: [String], file_path\n",
    "        \"\"\"\n",
    "        # read file\n",
    "        pchome_file = []\n",
    "        with open(file_path,encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for i,line in enumerate(lines):\n",
    "                line = re.sub('[^\\u4e00-\\u9fa5A-Za-z0-9]+','',line) #只留下中文、英文、數字\n",
    "                pchome_file.append(line.strip('\\n'))\n",
    "        \n",
    "        pchome_file = set(pchome_file)\n",
    "        \n",
    "        return pchome_file\n",
    "    \n",
    "    def merge_non_english(self,text):\n",
    "        '''\n",
    "        merge non english character together\n",
    "        :Input: [String], e.g. \"this is a 範 例 。\"\n",
    "        :Output: [String], e.g. \"this is a 範例。\"\n",
    "        '''\n",
    "        while re.search('[^A-Za-z\\s]+\\s[^A-Za-z\\s]+',text):\n",
    "            flag = re.search('[^A-Za-z\\s]+\\s[^A-Za-z\\s]+',text)\n",
    "            text = text[:flag.span()[0]] + text[flag.span()[0]:flag.span()[1]].replace(\" \", \"\") + text[flag.span()[1]:]\n",
    "            \n",
    "        return text\n",
    "        \n",
    "    def class_lexicon(self,class_name):\n",
    "        '''\n",
    "        Return class lexicon that have no duplicate\n",
    "        :Input: [String], class name of cilin\n",
    "        :Output: [list], lexicon of corresponding class name [String, String, String, String, ... , String]\n",
    "        '''\n",
    "        class_lexicon = []\n",
    "        #############################################\n",
    "        ## 將 class_name 所對應到的詞林大類裡，所有 term 取出，放到 class_lexicon 中\n",
    "        #############################################\n",
    "        \n",
    "        for _, (k_2, v_2) in enumerate(self.data[class_name].items()): #中類 type dict\n",
    "            if class_name == 'Market 商用詞':\n",
    "                if _ >= 1:  # 只針對 'Market 商用詞' 的第一個中類輸出字典\n",
    "                    break\n",
    "            for idx_3, v_3 in enumerate(v_2): #小類 type list\n",
    "\n",
    "                for idx_4 ,g_w in enumerate(v_3):\n",
    "                    if isinstance(g_w, list): #相似詞\n",
    "                        for idx_5 ,s_w in enumerate(g_w):\n",
    "                            if isinstance(s_w, list): #同義詞\n",
    "                                for term in s_w:\n",
    "                                    if '##' not in term:\n",
    "                                        #term = self.merge_non_english(term) # merge non english character together\n",
    "                                        #class_lexicon.append(term.lower()) #計算數量時關閉\n",
    "                                        term = re.sub('[^\\u4e00-\\u9fa5A-Za-z0-9]+','',term) #只留下中文、英文、數字\n",
    "                                        class_lexicon.append(term.lower())\n",
    "                            else:\n",
    "                                if '##' not in s_w:\n",
    "                                    #term = self.merge_non_english(s_w) # merge non english character together\n",
    "                                    #class_lexicon.append(s_w.lower()) #計算數量時關閉\n",
    "                                    term = re.sub('[^\\u4e00-\\u9fa5A-Za-z0-9]+','',s_w) #只留下中文、英文、數字\n",
    "                                    class_lexicon.append(term.lower())\n",
    "                    else:\n",
    "                        if '##' not in g_w:\n",
    "                            #term = self.merge_non_english(g_w) # merge non english character together\n",
    "                            #class_lexicon.append(g_w.lower()) #計算數量時關閉\n",
    "                            term = re.sub('[^\\u4e00-\\u9fa5A-Za-z0-9]+','',g_w) #只留下中文、英文、數字\n",
    "                            class_lexicon.append(term.lower())\n",
    "        \n",
    "        class_lexicon = set(class_lexicon) # delete duplicate in class_lexicon\n",
    "\n",
    "        if '##更改' in class_lexicon: \n",
    "            class_lexicon.remove('##更改') # delete '##更改' in class_lexicon\n",
    "\n",
    "        if '' in class_lexicon: \n",
    "            class_lexicon.remove('') # delete '' in class_lexicon\n",
    "\n",
    "        return class_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "772b1668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand 品牌 / 2284\n",
      "merge Brand 品牌 / 3299\n",
      "Name 名稱 / 1146\n",
      "Model 型號 / 1041\n",
      "Type 種類 / 11553\n",
      "merge Type 種類 / 11575\n",
      "Part 商品部位 / 130\n",
      "Customer 客群 / 97\n",
      "Event 事件 / 79\n",
      "Location 地名 / 90\n",
      "Place 場所 / 42\n",
      "Ad 廣告詞 / 601\n",
      "Market 商用詞 / 231\n",
      "P-Size 大小 / 58\n",
      "P-Material 材料 / 332\n",
      "P-Shape 外型 / 243\n",
      "P-Color 顏色 / 373\n",
      "P-TP 紋理花紋 / 100\n",
      "P-Flavor 味 / 86\n",
      "P-Theme 主題 / 463\n",
      "P-Other 其他特徵 / 1236\n",
      "Time 時間 / 52\n",
      "Quantity 量 / 26\n",
      "Number 數 / 250\n",
      "Operator 運算子 / 7\n",
      "Unit 單位 / 194\n",
      "test 測試 / 10\n",
      "number of term in Lexicon:  24045\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    o = OutPutLexicon('cilin_labeled_data_.json') \n",
    "    o.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7108cd60",
   "metadata": {},
   "source": [
    "### sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6533eb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch膜'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term = \" watch 膜\"\n",
    "# re.sub('[^\\u4e00-\\u9fa5A-Za-z0-9]+','',term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "147c58e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = [[1,2,3],[4,5,6],[99]]\n",
    "# b = [[99]]\n",
    "# s = set(tuple(i) for i in b)&set(tuple(i) for i in a)\n",
    "# [list(t) for t in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf732a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
